{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8fe8c3-d9e6-4afa-838e-fcd1757ea715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð Starting OCR Pipeline\n",
      "\n",
      "ð Processing Page 1/4 ...\n",
      "  Line 1: 1 1\n",
      "  Line 2: techno main Salt Lake\n",
      "  Line 3: ( Formerly techno india , salt lake )\n",
      "  Line 4: Name . Swiss malifrocoonariki00002012\n",
      "  Line 5: Roll No.130308231366.stream-CSAIL-\n",
      "  Line 6: invigilator's signature , \" you are - 4103125\n",
      "  Line 7: a b.a.\n",
      "  Line 8: \" \"\n",
      "  Line 9: # it into a bit of power . It was\n",
      "  Line 10: \" \" I say it , if it is\n",
      "  Line 11: \" Springfield \" SECRE . \" NEW . \"\n",
      "  Line 12: \" \" , \" *\n",
      "  Line 13: a b. \"\n",
      "  Line 14: \" U.O. \" \" ... \"\n",
      "  Line 15: \" \"\n",
      "  Line 16: 0 1\n",
      "\n",
      "ð Processing Page 2/4 ...\n",
      "  Line 1: 1 1\n",
      "  Line 2: 2. \"\n",
      "  Line 3: \" \" N. \" \" \" \" * . D.P. , ,\n",
      "  Line 4: \" Let\n",
      "  Line 5: DJ cross-validation ...\n",
      "  Line 6: \" \" \" \" itself : \" spin . \"\n",
      "  Line 7: Print export\n",
      "  Line 8: 0 0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      "ð Processing Page 3/4 ...\n",
      "  Line 1: U 20\n",
      "  Line 2: reveall , F.SCORE ... .\n",
      "  Line 3: 2, 1,0002,\n",
      "  Line 4: a b.\n",
      "  Line 5: T.P.\n",
      "  Line 6: \" \" \" Precision - with\n",
      "  Line 7: tpt-f.p.\n",
      "  Line 8: - 10.\n",
      "  Line 9: \" \" \"\n",
      "  Line 10: 2 .25th.\n",
      "  Line 11: \" 71043 - 13.\n",
      "  Line 12: c. 0.759\n",
      "  Line 13: \" What you need to be a member of the American Parliament Party\n",
      "  Line 14: \" JOY - \" ...\n",
      "  Line 15: 25 5.\n",
      "  Line 16: \" F.P.N. -\n",
      "  Line 17: \" #\n",
      "  Line 18: I raise positive note ...\n",
      "  Line 19: off-t.t.\n",
      "  Line 20: a b.\n",
      "  Line 21: 2- EB\n",
      "  Line 22: 20-05\n",
      "  Line 23: 5 References\n",
      "  Line 24: \" bias is a training terminology\n",
      "  Line 25: where the model\n",
      "  Line 26: 0\n",
      "  Line 27: Mississippi Democrats\n",
      "\n",
      "ð Processing Page 4/4 ...\n",
      "  Line 1: topper\n",
      "  Line 2: \" It-reduces - ... . \"\n",
      "  Line 3: \" by to produce variance , it can\n",
      "  Line 4: \" Mr. Lewis , Selwyn , Edwin\n",
      "  Line 5: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  Line 6: 0 References\n",
      "  Line 7: - First Semi since in 1932\n",
      "  Line 8: \" 7.000 - - -\n",
      "  Line 9: 42 2/2 \" 44 -\n",
      "  Line 10: \" B. \" I'm it , \" to come . \" So\n",
      "  Line 11: \" - - -\n",
      "  Line 12: 0 1/ 1/ 1/ 1/ 1. 1. 1. 1.2 1.\n",
      "  Line 13: 0,000000\n",
      "  Line 14: 25h.m.h.m.e.eatherland\n",
      "  Line 15: a fine : with a big time ever ! ... . It is now\n",
      "  Line 16: \" 0\" - - - - - - - - - - -\n",
      "  Line 17: \" SONGLE \" \" \" Not it's gentlemen . So ... . \"\n",
      "  Line 18: 0.0002500025000\n",
      "  Line 19: \" \" if it\n",
      "  Line 20: \" \" If . \" \"\n",
      "  Line 21: 75. Sullivan suffrage . \"\n",
      "  Line 22: 30. D.\n",
      "  Line 23: # - - MISSING to get his own . \" ... .\n",
      "  Line 24: \" you'll\n",
      "  Line 25: \" \" 58 -\n",
      "  Line 26: 35000\n",
      "  Line 27: 6 References\n",
      "  Line 28: \" \" MISSING Burden . Judge Kilburne .\n",
      "  Line 29: \" ? , \"\n",
      "  Line 30: \" 3.39 \"\n",
      "\n",
      "â",
      " OCR text saved to 23136_ocr_trocr.txt\n",
      "\n",
      "â",
      " Ground truth loaded from 23136.docx\n",
      "\n",
      "==================== OCR EVALUATION ====================\n",
      "CER: 0.7842\n",
      "WER: 1.0956\n",
      "========================================================\n",
      "â",
      " Full report saved to ocr_comparison_report_trocr.txt\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "#  TrOCR Handwritten OCR Pipeline for Scanned PDF Scripts\n",
    "# ======================================================\n",
    "# Author: OpenAI Assistant (GPT-5)\n",
    "# Description:\n",
    "# - Convert PDF pages to images\n",
    "# - Preprocess (grayscale, threshold, denoise)\n",
    "# - Segment handwritten lines\n",
    "# - Run TrOCR model for text recognition\n",
    "# - Compare output with ground truth from DOCX\n",
    "# ======================================================\n",
    "\n",
    "# --- STEP 0: Install dependencies (uncomment if needed) ---\n",
    "# !pip install opencv-python pillow numpy transformers torch torchvision jiwer matplotlib pdf2image python-docx\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from jiwer import wer, cer\n",
    "from pdf2image import convert_from_path\n",
    "import docx\n",
    "import torch\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 1: Preprocess scanned page\n",
    "# ------------------------------------------------------\n",
    "def preprocess_image(pil_image):\n",
    "    \"\"\"Preprocess scanned handwritten page: grayscale, normalize illumination, threshold.\"\"\"\n",
    "    img = np.array(pil_image.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Normalize illumination using morphological closing\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    bg = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    norm = cv2.divide(gray, bg, scale=255)\n",
    "\n",
    "    # Adaptive threshold\n",
    "    binary = cv2.adaptiveThreshold(norm, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 25, 15)\n",
    "\n",
    "    # Denoise small specks\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))\n",
    "    return binary\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 2: Line segmentation\n",
    "# ------------------------------------------------------\n",
    "def segment_lines(binary_img, min_height=20):\n",
    "    \"\"\"Segment text lines from binary image.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 3))\n",
    "    dilated = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    lines = []\n",
    "    for cnt in sorted(contours, key=lambda x: cv2.boundingRect(x)[1]):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if h > min_height:\n",
    "            line = binary_img[y:y + h, x:x + w]\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 3: Visualize segmented lines (optional)\n",
    "# ------------------------------------------------------\n",
    "def visualize_lines(lines, max_lines=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, l in enumerate(lines[:max_lines]):\n",
    "        plt.subplot(max_lines, 1, i + 1)\n",
    "        plt.imshow(255 - l, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 4: Initialize TrOCR model\n",
    "# ------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 5: Recognize a single line\n",
    "# ------------------------------------------------------\n",
    "def recognize_line(line_img):\n",
    "    \"\"\"Recognize handwritten text line using TrOCR.\"\"\"\n",
    "    image = Image.fromarray(255 - line_img).convert(\"RGB\")  # invert for TrOCR\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 6: Process a full PDF\n",
    "# ------------------------------------------------------\n",
    "def recognize_pdf(pdf_path, dpi=300):\n",
    "    \"\"\"Convert PDF to images, preprocess, segment, recognize each page.\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "    all_page_texts = []\n",
    "\n",
    "    for i, page in enumerate(pages, 1):\n",
    "        print(f\"\\nð Processing Page {i}/{len(pages)} ...\")\n",
    "        binary = preprocess_image(page)\n",
    "        lines = segment_lines(binary)\n",
    "\n",
    "        page_texts = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            txt = recognize_line(line)\n",
    "            page_texts.append(txt)\n",
    "            print(f\"  Line {idx + 1}: {txt}\")\n",
    "\n",
    "        all_page_texts.append(\"\\n\".join(page_texts))\n",
    "    return all_page_texts\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 7: Read ground truth from DOCX\n",
    "# ------------------------------------------------------\n",
    "def read_docx_text(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\\n\".join(p.text.strip() for p in doc.paragraphs if p.text.strip())\n",
    "    return text\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 8: Evaluate OCR output\n",
    "# ------------------------------------------------------\n",
    "def evaluate_text(predicted_text, ground_truth_text):\n",
    "    cer_score = cer(ground_truth_text.lower(), predicted_text.lower())\n",
    "    wer_score = wer(ground_truth_text.lower(), predicted_text.lower())\n",
    "    print(\"\\n==================== OCR EVALUATION ====================\")\n",
    "    print(f\"CER: {cer_score:.4f}\")\n",
    "    print(f\"WER: {wer_score:.4f}\")\n",
    "    print(\"========================================================\")\n",
    "    return cer_score, wer_score\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 9: Main execution\n",
    "# ------------------------------------------------------\n",
    "pdf_path = \"23136.pdf\"  # input PDF of handwritten answer script\n",
    "gt_path = \"23136.docx\"  # ground truth DOCX file\n",
    "\n",
    "print(\"ð Starting OCR Pipeline\")\n",
    "page_texts = recognize_pdf(pdf_path)\n",
    "\n",
    "# Combine recognized text\n",
    "recognized_text = \"\\n\\n\".join(page_texts)\n",
    "\n",
    "# Save OCR text\n",
    "with open(\"23136_ocr_trocr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(recognized_text)\n",
    "print(\"\\nâ",
    " OCR text saved to 23136_ocr_trocr.txt\")\n",
    "\n",
    "# Load ground truth\n",
    "ground_truth = read_docx_text(gt_path)\n",
    "print(\"\\nâ",
    " Ground truth loaded from\", gt_path)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_text(recognized_text, ground_truth)\n",
    "\n",
    "# Save final report\n",
    "with open(\"ocr_comparison_report_trocr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"OCR ACCURACY REPORT (TrOCR - Handwritten)\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(recognized_text + \"\\n\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\nGround Truth:\\n\")\n",
    "    f.write(ground_truth)\n",
    "print(\"â",
    " Full report saved to ocr_comparison_report_trocr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb76afeb-735f-4f82-b4c0-b86b300329e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð Starting OCR Pipeline\n",
      "\n",
      "ð Processing Page 1/2 ...\n",
      "  Line 1: 0 0\n",
      "  Line 2: techno main Salt Lake\n",
      "  Line 3: ( Formerly techno india , Salt Lake )\n",
      "  Line 4: Name . Shalich_dayakim____\n",
      "  Line 5: 0,\n",
      "  Line 6: \" In Vigilator's Signature Assessment Assistance Agency , of RAF.\n",
      "  Line 7: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  Line 8: past A\n",
      "  Line 9: \" ... \" ... and it . \" we know . \"\n",
      "  Line 10: system .\n",
      "  Line 11: \" Pfartzel . \"\n",
      "  Line 12: 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  Line 13: 0 1\n",
      "  Line 14: testing date .\n",
      "  Line 15: 0 0\n",
      "  Line 16: \" 0.\n",
      "\n",
      "ð Processing Page 2/2 ...\n",
      "  Line 1: of the years\n",
      "  Line 2: obias -\n",
      "  Line 3: \" \" is - \" only\n",
      "  Line 4: in the testing phase ...\n",
      "  Line 5: 0 1\n",
      "  Line 6: PROSLICTED .\n",
      "  Line 7: after\n",
      "  Line 8: is a one of a bit\n",
      "  Line 9: \" \"\n",
      "  Line 10: \" \" precisionists .\n",
      "  Line 11: scientific 10 - c. \"\n",
      "  Line 12: \" p.4 - ...\n",
      "  Line 13: \" If the possible state-size , \" or ,\n",
      "  Line 14: 42\"2d.d.d.e.e.e.\n",
      "  Line 15: 42\" \"\n",
      "  Line 16: \" The Government of America\n",
      "\n",
      "â",
      " OCR text saved to 23138_ocr_trocr.txt\n",
      "\n",
      "â",
      " Ground truth loaded from 23138.docx\n",
      "\n",
      "==================== OCR EVALUATION ====================\n",
      "CER: 0.8075\n",
      "WER: 0.9484\n",
      "========================================================\n",
      "â",
      " Full report saved to ocr_comparison_report_trocr.txt\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "#  TrOCR Handwritten OCR Pipeline for Scanned PDF Scripts\n",
    "# ======================================================\n",
    "# Author: OpenAI Assistant (GPT-5)\n",
    "# Description:\n",
    "# - Convert PDF pages to images\n",
    "# - Preprocess (grayscale, threshold, denoise)\n",
    "# - Segment handwritten lines\n",
    "# - Run TrOCR model for text recognition\n",
    "# - Compare output with ground truth from DOCX\n",
    "# ======================================================\n",
    "\n",
    "# --- STEP 0: Install dependencies (uncomment if needed) ---\n",
    "# !pip install opencv-python pillow numpy transformers torch torchvision jiwer matplotlib pdf2image python-docx\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from jiwer import wer, cer\n",
    "from pdf2image import convert_from_path\n",
    "import docx\n",
    "import torch\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 1: Preprocess scanned page\n",
    "# ------------------------------------------------------\n",
    "def preprocess_image(pil_image):\n",
    "    \"\"\"Preprocess scanned handwritten page: grayscale, normalize illumination, threshold.\"\"\"\n",
    "    img = np.array(pil_image.convert(\"RGB\"))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Normalize illumination using morphological closing\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
    "    bg = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    norm = cv2.divide(gray, bg, scale=255)\n",
    "\n",
    "    # Adaptive threshold\n",
    "    binary = cv2.adaptiveThreshold(norm, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 25, 15)\n",
    "\n",
    "    # Denoise small specks\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))\n",
    "    return binary\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 2: Line segmentation\n",
    "# ------------------------------------------------------\n",
    "def segment_lines(binary_img, min_height=20):\n",
    "    \"\"\"Segment text lines from binary image.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 3))\n",
    "    dilated = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    lines = []\n",
    "    for cnt in sorted(contours, key=lambda x: cv2.boundingRect(x)[1]):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if h > min_height:\n",
    "            line = binary_img[y:y + h, x:x + w]\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 3: Visualize segmented lines (optional)\n",
    "# ------------------------------------------------------\n",
    "def visualize_lines(lines, max_lines=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, l in enumerate(lines[:max_lines]):\n",
    "        plt.subplot(max_lines, 1, i + 1)\n",
    "        plt.imshow(255 - l, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 4: Initialize TrOCR model\n",
    "# ------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 5: Recognize a single line\n",
    "# ------------------------------------------------------\n",
    "def recognize_line(line_img):\n",
    "    \"\"\"Recognize handwritten text line using TrOCR.\"\"\"\n",
    "    image = Image.fromarray(255 - line_img).convert(\"RGB\")  # invert for TrOCR\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 6: Process a full PDF\n",
    "# ------------------------------------------------------\n",
    "def recognize_pdf(pdf_path, dpi=300):\n",
    "    \"\"\"Convert PDF to images, preprocess, segment, recognize each page.\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "    all_page_texts = []\n",
    "\n",
    "    for i, page in enumerate(pages, 1):\n",
    "        print(f\"\\nð Processing Page {i}/{len(pages)} ...\")\n",
    "        binary = preprocess_image(page)\n",
    "        lines = segment_lines(binary)\n",
    "\n",
    "        page_texts = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            txt = recognize_line(line)\n",
    "            page_texts.append(txt)\n",
    "            print(f\"  Line {idx + 1}: {txt}\")\n",
    "\n",
    "        all_page_texts.append(\"\\n\".join(page_texts))\n",
    "    return all_page_texts\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 7: Read ground truth from DOCX\n",
    "# ------------------------------------------------------\n",
    "def read_docx_text(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\\n\".join(p.text.strip() for p in doc.paragraphs if p.text.strip())\n",
    "    return text\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 8: Evaluate OCR output\n",
    "# ------------------------------------------------------\n",
    "def evaluate_text(predicted_text, ground_truth_text):\n",
    "    cer_score = cer(ground_truth_text.lower(), predicted_text.lower())\n",
    "    wer_score = wer(ground_truth_text.lower(), predicted_text.lower())\n",
    "    print(\"\\n==================== OCR EVALUATION ====================\")\n",
    "    print(f\"CER: {cer_score:.4f}\")\n",
    "    print(f\"WER: {wer_score:.4f}\")\n",
    "    print(\"========================================================\")\n",
    "    return cer_score, wer_score\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# STEP 9: Main execution\n",
    "# ------------------------------------------------------\n",
    "pdf_path = \"23138.pdf\"  # input PDF of handwritten answer script\n",
    "gt_path = \"23138.docx\"  # ground truth DOCX file\n",
    "\n",
    "print(\"ð Starting OCR Pipeline\")\n",
    "page_texts = recognize_pdf(pdf_path)\n",
    "\n",
    "# Combine recognized text\n",
    "recognized_text = \"\\n\\n\".join(page_texts)\n",
    "\n",
    "# Save OCR text\n",
    "with open(\"23138_ocr_trocr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(recognized_text)\n",
    "print(\"\\nâ",
    " OCR text saved to 23138_ocr_trocr.txt\")\n",
    "\n",
    "# Load ground truth\n",
    "ground_truth = read_docx_text(gt_path)\n",
    "print(\"\\nâ",
    " Ground truth loaded from\", gt_path)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_text(recognized_text, ground_truth)\n",
    "\n",
    "# Save final report\n",
    "with open(\"ocr_comparison_report_trocr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"OCR ACCURACY REPORT (TrOCR - Handwritten)\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(recognized_text + \"\\n\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\nGround Truth:\\n\")\n",
    "    f.write(ground_truth)\n",
    "print(\"â",
    " Full report saved to ocr_comparison_report_trocr.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
