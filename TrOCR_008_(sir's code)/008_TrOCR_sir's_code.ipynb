{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz-zyvwlk5CR",
        "outputId": "dad6e139-48c3-4cde-c0ea-34b2a7f2fd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.57.1)\n",
            "Requirement already satisfied: accelerate>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (11.3.0)\n",
            "Requirement already satisfied: pdf2image>=1.16.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (1.17.0)\n",
            "Requirement already satisfied: PyMuPDF>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (1.26.5)\n",
            "Requirement already satisfied: python-docx>=0.8.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (3.10.0)\n",
            "Requirement already satisfied: jiwer>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (4.0.0)\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (3.9.1)\n",
            "Requirement already satisfied: rouge-score>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (0.1.2)\n",
            "Requirement already satisfied: bert-score>=0.3.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (0.3.13)\n",
            "Requirement already satisfied: sentencepiece>=0.1.98 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (0.2.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (4.67.1)\n",
            "Requirement already satisfied: tokenizers>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 13)) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.0->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx>=0.8.11->-r requirements.txt (line 23)) (5.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 25)) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer>=3.0.3->-r requirements.txt (line 28)) (8.3.0)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer>=3.0.3->-r requirements.txt (line 28)) (3.14.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.1->-r requirements.txt (line 29)) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 30)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 30)) (1.17.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from bert-score>=0.3.11->-r requirements.txt (line 31)) (2.2.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 13)) (1.1.10)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score>=0.3.11->-r requirements.txt (line 31)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.1->bert-score>=0.3.11->-r requirements.txt (line 31)) (2025.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 13)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 13)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 13)) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Header and Description**"
      ],
      "metadata": {
        "id": "meSkG9FAlH-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoFtfy5KpBi5",
        "outputId": "84826ea8-2be0-42db-c8a2-fc40ce6a996d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.11 [186 kB]\n",
            "Fetched 186 kB in 0s (733 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126718 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.11_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "#  TrOCR Handwritten OCR Pipeline for Scanned PDF Scripts\n",
        "# ======================================================\n",
        "# Author: OpenAI Assistant (GPT-5)\n",
        "# Description:\n",
        "# - Convert PDF pages to images\n",
        "# - Preprocess (grayscale, threshold, denoise)\n",
        "# - Segment handwritten lines\n",
        "# - Run TrOCR model for text recognition\n",
        "# - Compare output with ground truth from DOCX\n",
        "# ======================================================\n",
        "\n",
        "# --- STEP 0: Install dependencies (uncomment if needed) ---\n",
        "# !pip install opencv-python pillow numpy transformers torch torchvision jiwer matplotlib pdf2image python-docx\n"
      ],
      "metadata": {
        "id": "TP-TusXYlEut"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "2dhtxPvdlQNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from jiwer import wer, cer\n",
        "from pdf2image import convert_from_path\n",
        "import docx\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "6UEth2-llGeW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1: Preprocess Scanned Page**"
      ],
      "metadata": {
        "id": "RNM2T1iOlZI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 1: Preprocess scanned page\n",
        "# ------------------------------------------------------\n",
        "def preprocess_image(pil_image):\n",
        "    \"\"\"Preprocess scanned handwritten page: grayscale, normalize illumination, threshold.\"\"\"\n",
        "    img = np.array(pil_image.convert(\"RGB\"))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Normalize illumination using morphological closing\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
        "    bg = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
        "    norm = cv2.divide(gray, bg, scale=255)\n",
        "\n",
        "    # Adaptive threshold\n",
        "    binary = cv2.adaptiveThreshold(norm, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 25, 15)\n",
        "\n",
        "    # Denoise small specks\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))\n",
        "    return binary\n"
      ],
      "metadata": {
        "id": "cjxJ-Hz4lWR4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 2: Line Segmentation**"
      ],
      "metadata": {
        "id": "GHy0pn_olcwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 2: Line segmentation\n",
        "# ------------------------------------------------------\n",
        "def segment_lines(binary_img, min_height=20):\n",
        "    \"\"\"Segment text lines from binary image.\"\"\"\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 3))\n",
        "    dilated = cv2.dilate(binary_img, kernel, iterations=1)\n",
        "\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    lines = []\n",
        "    for cnt in sorted(contours, key=lambda x: cv2.boundingRect(x)[1]):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        if h > min_height:\n",
        "            line = binary_img[y:y + h, x:x + w]\n",
        "            lines.append(line)\n",
        "    return lines\n"
      ],
      "metadata": {
        "id": "k4hTYQHllfgG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 3: Visualize Lines (Optional)**"
      ],
      "metadata": {
        "id": "uSxSmggXlhYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 3: Visualize segmented lines (optional)\n",
        "# ------------------------------------------------------\n",
        "def visualize_lines(lines, max_lines=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, l in enumerate(lines[:max_lines]):\n",
        "        plt.subplot(max_lines, 1, i + 1)\n",
        "        plt.imshow(255 - l, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "YEQT4rBzll3c"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 4: Initialize TrOCR Model**"
      ],
      "metadata": {
        "id": "wxQ7jj3llnnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 4: Initialize TrOCR model\n",
        "# ------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY6IhkwvlqMV",
        "outputId": "f3881a88-a693-4be4-b2fd-c13bdb8401f6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 5: Recognize a Single Line**"
      ],
      "metadata": {
        "id": "wDxxpCM1lr_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 5: Recognize a single line\n",
        "# ------------------------------------------------------\n",
        "def recognize_line(line_img):\n",
        "    \"\"\"Recognize handwritten text line using TrOCR.\"\"\"\n",
        "    image = Image.fromarray(255 - line_img).convert(\"RGB\")  # invert for TrOCR\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "QU8scRfSlujc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 6: Process a Full PDF**"
      ],
      "metadata": {
        "id": "aq87UjmPlv7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 6: Process a full PDF\n",
        "# ------------------------------------------------------\n",
        "def recognize_pdf(pdf_path, dpi=300):\n",
        "    \"\"\"Convert PDF to images, preprocess, segment, recognize each page.\"\"\"\n",
        "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
        "    all_page_texts = []\n",
        "\n",
        "    for i, page in enumerate(pages, 1):\n",
        "        print(f\"\\nðŸ“„ Processing Page {i}/{len(pages)} ...\")\n",
        "        binary = preprocess_image(page)\n",
        "        lines = segment_lines(binary)\n",
        "\n",
        "        page_texts = []\n",
        "        for idx, line in enumerate(lines):\n",
        "            txt = recognize_line(line)\n",
        "            page_texts.append(txt)\n",
        "            print(f\"  Line {idx + 1}: {txt}\")\n",
        "\n",
        "        all_page_texts.append(\"\\n\".join(page_texts))\n",
        "    return all_page_texts\n"
      ],
      "metadata": {
        "id": "vw3I_5tblyp8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 7: Read Ground Truth**"
      ],
      "metadata": {
        "id": "CKHfqPYPl0A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 7: Read ground truth from DOCX\n",
        "# ------------------------------------------------------\n",
        "def read_docx_text(docx_path):\n",
        "    doc = docx.Document(docx_path)\n",
        "    text = \"\\n\".join(p.text.strip() for p in doc.paragraphs if p.text.strip())\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "c2qiUPV5l3a0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 8: Evaluate OCR Output**"
      ],
      "metadata": {
        "id": "UQrWz7mhl5O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 8: Evaluate OCR output\n",
        "# ------------------------------------------------------\n",
        "def evaluate_text(predicted_text, ground_truth_text):\n",
        "    cer_score = cer(ground_truth_text.lower(), predicted_text.lower())\n",
        "    wer_score = wer(ground_truth_text.lower(), predicted_text.lower())\n",
        "    print(\"\\n==================== OCR EVALUATION ====================\")\n",
        "    print(f\"CER: {cer_score:.4f}\")\n",
        "    print(f\"WER: {wer_score:.4f}\")\n",
        "    print(\"========================================================\")\n",
        "    return cer_score, wer_score\n"
      ],
      "metadata": {
        "id": "SPJDlQsQl8BM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 9: Main Execution**"
      ],
      "metadata": {
        "id": "JdjmQUjOl9Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 9: Main execution\n",
        "# ------------------------------------------------------\n",
        "pdf_path = \"008_scanned.pdf\"  # input PDF of handwritten answer script\n",
        "gt_path = \"008_ground_truth.docx\"  # ground truth DOCX file\n",
        "\n",
        "print(\"ðŸš€ Starting OCR Pipeline\")\n",
        "page_texts = recognize_pdf(pdf_path)\n",
        "\n",
        "# Combine recognized text\n",
        "recognized_text = \"\\n\\n\".join(page_texts)\n",
        "\n",
        "# Save OCR text\n",
        "with open(\"008_trocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(recognized_text)\n",
        "print(\"\\nâœ… OCR text saved to 008_trocr_output.txt\")\n",
        "\n",
        "# Load ground truth\n",
        "ground_truth = read_docx_text(gt_path)\n",
        "print(\"\\nâœ… Ground truth loaded from\", gt_path)\n",
        "\n",
        "# Evaluate\n",
        "evaluate_text(recognized_text, ground_truth)\n",
        "\n",
        "# Save final report\n",
        "with open(\"008_TrOCR_comparison_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"OCR ACCURACY REPORT (TrOCR - Handwritten)\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(recognized_text + \"\\n\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\nGround Truth:\\n\")\n",
        "    f.write(ground_truth)\n",
        "print(\"âœ… Full report saved to 008_TrOCR_comparison_report.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n2Ld5Cul_Tk",
        "outputId": "24ecc673-6f22-4eab-ae33-75b047e42eed"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting OCR Pipeline\n",
            "\n",
            "ðŸ“„ Processing Page 1/4 ...\n",
            "  Line 1: \" \" I did not go out . \"\n",
            "  Line 2: \" \" I understand it\n",
            "  Line 3: a b.a.a.a.b.a.a.a.a.a\n",
            "  Line 4: techno main Salt Lake .\n",
            "  Line 5: \" Formerly , techno India , Salt Lake ) ... .\n",
            "  Line 6: \" 51, \" D. 0 )\n",
            "  Line 7: Nameafter graduating with the\n",
            "  Line 8: \" \" K. \" -\n",
            "  Line 9: Roll No. \" 12030822008____0000sroom .CEA.A.200pick\n",
            "  Line 10: 1952 53\n",
            "  Line 11: 2 Part A.\n",
            "  Line 12: # the most common expenials leaving ducks are- Classifications ,\n",
            "  Line 13: 0,\n",
            "  Line 14: mini bottoms . \" Let\n",
            "  Line 15: \" \" \" ... \" \" ... . \"\n",
            "  Line 16: 3 Language judgement personnel in CO ) and this form ( or just the\n",
            "  Line 17: \" 7. ) \" 5.5 :\n",
            "  Line 18: a member of the Spanish Spanish American diplomat\n",
            "  Line 19: # 0 -\n",
            "  Line 20: This is now noxious mind since its return to\n",
            "  Line 21: and it was the best of the best of the best of the best of the best of the\n",
            "  Line 22: 0.\n",
            "  Line 23: Part B.\n",
            "  Line 24: \" 2\"\n",
            "  Line 25: \" I'll get it to it ... ... . \"\n",
            "  Line 26: 0 1\n",
            "  Line 27: \" I'll #\n",
            "  Line 28: a b.i.i.e.e.e.e.e.e.e\n",
            "  Line 29: \" I'm not\n",
            "  Line 30: 25 I ...\n",
            "  Line 31: 0 0\n",
            "  Line 32: \" F. \" \" I ) I ) I ) I ) I ) I say\n",
            "  Line 33: \" \"\n",
            "\n",
            "ðŸ“„ Processing Page 2/4 ...\n",
            "  Line 1: ' 50\n",
            "  Line 2: O.Hackeray - # PP.P.P.S. TN.\n",
            "  Line 3: 2 2 Rheugian . \"\n",
            "  Line 4: 0-Tp-t.fp.\n",
            "  Line 5: 2nd century . Sir. Fitzroydon\n",
            "  Line 6: Recall - -\n",
            "  Line 7: . \" TP +4 FN. \"\n",
            "  Line 8: for COVID 19 \" They are the first time old .\n",
            "  Line 9: \" \" \" \" \" \" \"\n",
            "  Line 10: \" In question classification problem , IN.82 \" ... .\n",
            "  Line 11: \" What it'll be it into it . It'll be sure it into it . It's\n",
            "  Line 12: \" \"\n",
            "  Line 13: away ,\n",
            "  Line 14: \" \"\n",
            "  Line 15: # F.N.E.S.S.S.P.000\"0005000\n",
            "  Line 16: \" \" \" \" \" - - ... if , you get you got your way . \"\n",
            "  Line 17: \" 0\" \" 1.2 1.\n",
            "  Line 18: Tp.10 .\n",
            "  Line 19: a b.d.\n",
            "  Line 20: 2 1 0\n",
            "  Line 21: \" Precision \" . \" not # \" is . \"\n",
            "  Line 22: also also\n",
            "  Line 23: TPTF P.\n",
            "  Line 24: 0/\n",
            "  Line 25: \" \" TPP + FN.\n",
            "  Line 26: 2 1 5.\n",
            "  Line 27: 0 3 .\n",
            "  Line 28: 5 4 10\n",
            "  Line 29: I 285\n",
            "  Line 30: \" 34482 - 55. \"\n",
            "  Line 31: \" \" FP4TN.\n",
            "  Line 32: 3482 3.3\n",
            "  Line 33: \" \" I \" - #\n",
            "  Line 34: \" \"\n",
            "  Line 35: itself nine - it - are\n",
            "  Line 36: # the I say that\n",
            "  Line 37: ' 69 ' 70\n",
            "  Line 38: 0 1/\n",
            "  Line 39: # you do\n",
            "  Line 40: # 1/ 1,\n",
            "  Line 41: \" 2/2 \"2 -2\n",
            "  Line 42: \" 550, \"\n",
            "  Line 43: # I'll # question .\n",
            "  Line 44: \" Blair's wife .\n",
            "  Line 45: \" \" P. , ,\n",
            "\n",
            "ðŸ“„ Processing Page 3/4 ...\n",
            "  Line 1: to enhance\n",
            "  Line 2: 0-\n",
            "  Line 3: 25 I 55\n",
            "  Line 4: 0 0 0 0 0 0 0 0 0\n",
            "  Line 5: 0 0000 0,000\n",
            "  Line 6: 1 0\n",
            "  Line 7: overfitting\n",
            "  Line 8: 0 0\n",
            "  Line 9: non-linear relations .\n",
            "  Line 10: \" \" 0\" \" 0. 0.5. 0.2 .\n",
            "  Line 11: \" ... . \"\n",
            "  Line 12: 0.T.\n",
            "  Line 13: 0.000000000000000000000000000000000000000000000000000000\n",
            "  Line 14: \" if - say \" , \"\n",
            "  Line 15: ' Underfitting .\n",
            "  Line 16: displaystyle x. y. 1 y. y. y.\n",
            "  Line 17: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  Line 18: as Plays to Present .\n",
            "  Line 19: 0 0\n",
            "  Line 20: 0 !\n",
            "  Line 21: 42' 58\n",
            "  Line 22: 0 0\n",
            "  Line 23: # on - \" \" ... \" \"\n",
            "  Line 24: \" \" \" \" \" \" \" \" \" \" - - NOTING your\n",
            "  Line 25: \" \" \" - I ) ... . AT.\n",
            "\n",
            "ðŸ“„ Processing Page 4/4 ...\n",
            "  Line 1: 1 734\n",
            "  Line 2: \" It is said in\n",
            "  Line 3: \" Highway .\n",
            "  Line 4: Low Variance\n",
            "  Line 5: 25 C.\n",
            "  Line 6: 0 0\n",
            "  Line 7: Loui Bias .\n",
            "  Line 8: \" it ,\n",
            "  Line 9: \" Brian . \" D.000 -\n",
            "  Line 10: a b c.m.m.m.r.r.r.r.r.\n",
            "  Line 11: \" I say .000\n",
            "  Line 12: 1 000\n",
            "  Line 13: Colour , bias \" and money\n",
            "  Line 14: 0 1\n",
            "  Line 15: \" \" Currie .\n",
            "  Line 16: \" \" ... \" \" \" # ... . \" I know , my ,\n",
            "  Line 17: a member of the House of Representatives of Representatives from the House of Representatives\n",
            "  Line 18: 36' 58 )\n",
            "  Line 19: \" \" \" I ask ? \" We know\n",
            "  Line 20: \" \" 0.2 \"\n",
            "  Line 21: \" \" ... \" \" ... . \" It is now out of\n",
            "  Line 22: \" \" I understand that it was not yet\n",
            "  Line 23: \" \" ... \" ... \" \" It's . \" ... join . \"\n",
            "  Line 24: \" \"\n",
            "  Line 25: \" Random Classifier ( ( O.S.A.C.S. ) . \"\n",
            "  Line 26: \" \" \" U. ) \" I'm ... . \" I'm sure . \" . \"\n",
            "  Line 27: \" 50\n",
            "  Line 28: 52 28 S. 55 E 52 467 S. 5. W 52 467 W 52 4\n",
            "  Line 29: \" 50\n",
            "  Line 30: \" \" \" \" Taper . \" ...\n",
            "  Line 31: 32 3/\n",
            "  Line 32: RECAIL \" T.N.\n",
            "  Line 33: c.r.Tp. FN.\n",
            "  Line 34: 0 0 0 0 0 0 0 0\n",
            "\n",
            "âœ… OCR text saved to 008_trocr_output.txt\n",
            "\n",
            "âœ… Ground truth loaded from 008_ground_truth.docx\n",
            "\n",
            "==================== OCR EVALUATION ====================\n",
            "CER: 0.7789\n",
            "WER: 0.9790\n",
            "========================================================\n",
            "âœ… Full report saved to 008_TrOCR_comparison_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIsyZcOTmCYt"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}